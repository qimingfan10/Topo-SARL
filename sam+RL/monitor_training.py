"""
è®­ç»ƒç›‘æ§è„šæœ¬
"""
import os
import sys
import time
import json
from pathlib import Path
from datetime import datetime, timedelta


def parse_log_file(log_file):
    """è§£æè®­ç»ƒæ—¥å¿—"""
    if not os.path.exists(log_file):
        return None
    
    with open(log_file, 'r') as f:
        lines = f.readlines()
    
    info = {
        'total_lines': len(lines),
        'status': 'unknown',
        'episodes': 0,
        'merges': 0,
        'samples': 0,
        'last_10_lines': lines[-10:] if len(lines) >= 10 else lines
    }
    
    # æ£€æŸ¥çŠ¶æ€
    if any('è®­ç»ƒå®Œæˆ' in line for line in lines):
        info['status'] = 'completed'
    elif any('Error' in line or 'Traceback' in line for line in lines):
        info['status'] = 'error'
    elif any('å¼€å§‹è®­ç»ƒ' in line for line in lines):
        info['status'] = 'running'
    else:
        info['status'] = 'starting'
    
    # ç»Ÿè®¡ä¿¡æ¯
    for line in lines:
        if 'ç”Ÿæˆå€™é€‰æ•°' in line:
            info['samples'] += 1
        if '[MERGE]' in line and 'é€‰ä¸­å€™é€‰æ•°' in line:
            info['merges'] += 1
    
    # ä¼°ç®—episodesï¼ˆæ¯ä¸ªepisodeå¤§çº¦æœ‰å¤šä¸ªå€™é€‰ç”Ÿæˆï¼‰
    info['episodes'] = info['samples'] // 3  # ç²—ç•¥ä¼°è®¡
    
    return info


def find_checkpoints(checkpoint_dir):
    """æŸ¥æ‰¾ä¿å­˜çš„æ£€æŸ¥ç‚¹"""
    if not os.path.exists(checkpoint_dir):
        return []
    
    checkpoints = []
    for f in os.listdir(checkpoint_dir):
        if f.endswith('.zip'):
            path = os.path.join(checkpoint_dir, f)
            size = os.path.getsize(path) / (1024 * 1024)  # MB
            mtime = os.path.getmtime(path)
            checkpoints.append({
                'name': f,
                'size_mb': size,
                'modified': datetime.fromtimestamp(mtime).strftime('%Y-%m-%d %H:%M:%S')
            })
    
    return sorted(checkpoints, key=lambda x: x['modified'], reverse=True)


def find_tensorboard_logs(log_dir):
    """æŸ¥æ‰¾TensorBoardæ—¥å¿—"""
    if not os.path.exists(log_dir):
        return []
    
    logs = []
    for root, dirs, files in os.walk(log_dir):
        for d in dirs:
            if d.startswith('PPO_'):
                path = os.path.join(root, d)
                logs.append({
                    'name': d,
                    'path': path
                })
    
    return logs


def display_status(log_file, checkpoint_dir, log_dir):
    """æ˜¾ç¤ºè®­ç»ƒçŠ¶æ€"""
    os.system('clear' if os.name != 'nt' else 'cls')
    
    print("=" * 80)
    print(" " * 25 + "SAM2 + RL è®­ç»ƒç›‘æ§")
    print("=" * 80)
    print()
    
    # å½“å‰æ—¶é—´
    print(f"æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # è§£ææ—¥å¿—
    info = parse_log_file(log_file)
    
    if info is None:
        print("âš ï¸  æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨")
        print(f"   è·¯å¾„: {log_file}")
    else:
        # è®­ç»ƒçŠ¶æ€
        status_emoji = {
            'running': 'ğŸŸ¢',
            'completed': 'âœ…',
            'error': 'âŒ',
            'starting': 'ğŸŸ¡',
            'unknown': 'âšª'
        }
        
        print(f"è®­ç»ƒçŠ¶æ€: {status_emoji.get(info['status'], '?')} {info['status'].upper()}")
        print()
        
        # ç»Ÿè®¡ä¿¡æ¯
        print("è®­ç»ƒè¿›åº¦:")
        print(f"  Episodes (ä¼°è®¡): {info['episodes']}")
        print(f"  å€™é€‰ç”Ÿæˆæ¬¡æ•°: {info['samples']}")
        print(f"  Mergeæ‰§è¡Œæ¬¡æ•°: {info['merges']}")
        print(f"  æ—¥å¿—è¡Œæ•°: {info['total_lines']}")
        print()
        
        # æœ€åå‡ è¡Œ
        print("æœ€å10è¡Œæ—¥å¿—:")
        print("-" * 80)
        for line in info['last_10_lines']:
            print(line.rstrip())
        print("-" * 80)
        print()
    
    # æ£€æŸ¥ç‚¹
    checkpoints = find_checkpoints(checkpoint_dir)
    if checkpoints:
        print(f"å·²ä¿å­˜çš„æ£€æŸ¥ç‚¹ ({len(checkpoints)}):")
        for cp in checkpoints[:5]:  # åªæ˜¾ç¤ºæœ€æ–°çš„5ä¸ª
            print(f"  {cp['name']} | {cp['size_mb']:.1f} MB | {cp['modified']}")
    else:
        print("å·²ä¿å­˜çš„æ£€æŸ¥ç‚¹: 0")
    print()
    
    # TensorBoardæ—¥å¿—
    tb_logs = find_tensorboard_logs(log_dir)
    if tb_logs:
        print(f"TensorBoardæ—¥å¿— ({len(tb_logs)}):")
        for log in tb_logs:
            print(f"  {log['name']} | {log['path']}")
        print()
        print("æŸ¥çœ‹TensorBoard:")
        print(f"  tensorboard --logdir {log_dir} --port 6006")
    else:
        print("TensorBoardæ—¥å¿—: æ— ")
    print()
    
    # å¸®åŠ©ä¿¡æ¯
    print("=" * 80)
    print("ç›‘æ§å‘½ä»¤:")
    print(f"  æŸ¥çœ‹å®Œæ•´æ—¥å¿—: tail -f {log_file}")
    print(f"  åœæ­¢è®­ç»ƒ: pkill -f 'python3 train.py'")
    print(f"  æŸ¥çœ‹è¿›ç¨‹: ps aux | grep train.py")
    print()
    print("æŒ‰ Ctrl+C é€€å‡ºç›‘æ§")
    print("=" * 80)


def main():
    """ä¸»å‡½æ•°"""
    log_file = '/home/ubuntu/sam+RL/logs/full_training_v2.log'
    checkpoint_dir = '/home/ubuntu/sam+RL/checkpoints'
    log_dir = '/home/ubuntu/sam+RL/logs'
    
    print("å¯åŠ¨è®­ç»ƒç›‘æ§...")
    print(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
    print()
    print("æ¯5ç§’æ›´æ–°ä¸€æ¬¡ï¼ŒæŒ‰ Ctrl+C é€€å‡º")
    time.sleep(2)
    
    try:
        while True:
            display_status(log_file, checkpoint_dir, log_dir)
            time.sleep(5)
    except KeyboardInterrupt:
        print("\n\nç›‘æ§å·²åœæ­¢")


if __name__ == "__main__":
    main()

